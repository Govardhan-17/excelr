{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRmkSTocql9h",
        "outputId": "a57cf875-2369-48a8-ff11-061ecd951e07"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Lowercase Text:\n",
            "this is a simple example to demonstrate text processing using python , nltk , and spacy .\n",
            "\n",
            "Text After Removing Stopwords:\n",
            "simple example demonstrate text processing using python , nltk , spacy .\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n",
        "\n",
        "# Download NLTK stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load spaCy English model\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "\n",
        "# Define the input text\n",
        "text = \"This is a simple example to demonstrate text processing using Python, NLTK, and spaCy.\"\n",
        "\n",
        "# Step 1: Convert text to lowercase using spaCy\n",
        "doc = nlp(text)\n",
        "lowercase_text = \" \".join([token.text.lower() for token in doc])\n",
        "print(\"Lowercase Text:\")\n",
        "print(lowercase_text)\n",
        "\n",
        "# Step 2: Remove stopwords using NLTK\n",
        "stop_words = set(stopwords.words(\"english\"))\n",
        "filtered_words = [word for word in lowercase_text.split() if word not in stop_words]\n",
        "\n",
        "# Join filtered words into a single string\n",
        "filtered_text = \" \".join(filtered_words)\n",
        "\n",
        "print(\"\\nText After Removing Stopwords:\")\n",
        "print(filtered_text)\n"
      ]
    }
  ]
}